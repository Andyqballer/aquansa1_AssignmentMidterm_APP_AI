# Applied AI-Midterm


#### The Models are seperated into their own notebook files. The file aquansa1_AssignmentMidterm_APP_AI.ipynb contains the full file with all outputs.

### Introduction to SRGANs
Super Resolution GAN (SRGAN) Links to an external site is a deep learning architecture that generates high-resolution images from low-resolution imagesÂ using GANs and CNNs. SRGAN uses a generator network to create high-resolution images as similar as feasible to the real ones and a discriminator network to distinguish between them. 
Training involves sending low-resolution photos to the generator, which generates high-resolution images. The discriminator then examines the high-resolution image and gives the generator feedback to improve it.
Generation and discriminator networks are trained iteratively until images are good enough. Super Resolution GAN is used in medical imaging, satellite photography, and video processing. It improves low-resolution images for analysis and decision-making.

### Train a binary classifier (called A) on the dataset using transfer learning (exactly like Assignment 1). The images should be downscaled to 128x128
The Model A file contains this assignment one requirement. 


### Train the SRGAN to generate 128x128 images. Each image of the training is downscaled to 32x32.
The original images is first downsized from their original shapes to a standard 32x32x3 image size, and then a loop was created to downsize the images. 

### Utilize the images generated by SRGAN in order to train a new model (called B)
The Model B file satisfies this requirement.

### Train the SRGAN for at least 150 epochs
This requirment is done in the SRGAN File

### Apply normalization and image transformation, and demonstrate some of the transformed samples


### Compare the performance of both models using different metrics such as F1, Accuracy, AUC
Comparing the two models; A and B, was the final requirement.

Comparing the two loss and accuracy curves, including the confussion matrix, Model B performed better than expected for generated images, but not as well as the original. 
Logiacally, there are several considerations why there is a difference and why there is a drastic overfitting within Model B. This is attributed to the number of training Epochs that were ran. 
The original requirment for the dataset with low pixel density images was 500 Epochs, but because  of time and memory constraints, the number was reduced to 150. Additional training would lead to results that are both better and more accurate.


## Basic Steps to create and run an SRGAN to take 32x32x3 images to 128x128x3 then perform binary classification

1. Gather and preprocess your dataset of 32x32x3 images. It includes resizing the images to 128x128x3, normalizing pixel values, and splitting the dataset into training and testing sets.

2. Train the SRGAN model on the training set of 32x32x3 images to generate 128x128x3 images. SRGAN is a deep neural network that uses a combination of convolutional and deconvolutional layers, as well as residual blocks, to generate high-quality images.

3. Fine-tune the SRGAN model on the training set of 128x128x3 images. This step involves using a discriminator network to differentiate between real and generated images, and adjusting the weights of the SRGAN network based on the feedback from the discriminator.

4. Evaluate the performance of the SRGAN model on the test set of 128x128x3 images. This includes calculating metrics such as peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) to measure the similarity between the generated and real images.

5. Train a binary classifier on the generated 128x128x3 images to perform binary classification. A variety of machine learning algorithms, such as logistic regression, support vector machines (SVMs), or deep neural networks can be considered.

6. Evaluate the performance of the binary classifier on a separate test set of generated 128x128x3 images. Calculating metrics such as accuracy, precision, recall, and F1 score to measure the effectiveness of the classifier in differentiating between the two classes can be considered.

7. Fine-tune the SRGAN model and binary classifier as required based on the evaluation results. It can be done by adjusting hyperparameters, optimizing the network architecture, or retraining the model on additional data.
